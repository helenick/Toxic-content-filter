{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d3b04218-0413-4e6c-8751-5d8a404d73a9",
    "_uuid": "0bca9739b82d5d51e1229243e03ea1b6db35c17e"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "This snippet shows how to use NBSVM (Naive Bayes - Support Vector Machine) to create a toxic content detector. NBSVM was introduced by Sida Wang and Chris Manning in the paper [Baselines and Bigrams: Simple, Good Sentiment and Topic Classiﬁcation](https://nlp.stanford.edu/pubs/sidaw12_simple_sentiment.pdf). \n",
    "Model is capable to detect different types of toxicity like threats, obscenity, insults, and identity-based hate. A dataset of comments from Wikipedia’s talk page edits was used as a dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "ef06cd19-66b6-46bc-bf45-184e12d3f7d4",
    "_uuid": "cca038ca9424a3f66e10262fc9129de807b5f855"
   },
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3996a226-e1ca-4aa8-b39f-6524d4dadb07",
    "_uuid": "2c18461316f17d1d323b1959c8eb4e5448e8a44e"
   },
   "source": [
    "## Looking at the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset here is from wiki corpus dataset which was rated by human raters for toxicity.\n",
    "The corpus contains 63M comments from discussions relating to user pages and articles dating from 2004-2015. \n",
    "\n",
    "Different platforms/sites can have different standards for their toxic screening process. Hence the comments are tagged in the following five categories\n",
    "* toxic\n",
    "* severe_toxic\n",
    "* obscene\n",
    "* threat\n",
    "* insult\n",
    "* identity_hate\n",
    "\n",
    "The tagging was done via **crowdsourcing** which means that the dataset was rated by different people and the tagging might not be 100% accurate too. \n",
    "\n",
    "The [source paper](https://arxiv.org/pdf/1610.08914.pdf) contains more interesting details about the dataset creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "a494f561-0c2f-4a38-8973-6b60c22da357",
    "_uuid": "f70ebe669fcf6b434c595cf6fb7a76120bf7809c"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "subm = pd.read_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "5ddb337b-c9b2-4fec-9652-cb26769dc3c6",
    "_uuid": "5f5269c56ea6ded273881b0d4dcdb6af83a3e089",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>00025465d4725e87</td>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0002bcb3da6cb337</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>00031b1e95af7921</td>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>00037261f536c51d</td>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>00040093b2687caa</td>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "5  00025465d4725e87  \"\\n\\nCongratulations from me as well, use the ...      0   \n",
       "6  0002bcb3da6cb337       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1   \n",
       "7  00031b1e95af7921  Your vandalism to the Matt Shirvington article...      0   \n",
       "8  00037261f536c51d  Sorry if the word 'nonsense' was offensive to ...      0   \n",
       "9  00040093b2687caa  alignment on this subject and which are contra...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  \n",
       "5             0        0       0       0              0  \n",
       "6             1        1       0       1              0  \n",
       "7             0        0       0       0              0  \n",
       "8             0        0       0       0              0  \n",
       "9             0        0       0       0              0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2ea37597-02f7-43cf-ad16-a3d50aac1aba",
    "_uuid": "5c4c716de98a4b1c2ecc0e516e67813b4fc1473e"
   },
   "source": [
    "The length of the comments varies a lot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "fd3fe158-4d7f-4b30-ac15-42605240ea4f",
    "_uuid": "9c1a3f81397199fa250a2b642edc7fbc5f9f504e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(394.0732213246768, 590.7202819048923, 5000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens = train.comment_text.str.len()\n",
    "lens.mean(), lens.std(), lens.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1b221e62-e23f-422a-939d-6747edf2d613",
    "_uuid": "bfdcf59624717b37ca4ffc0c99d2c28a2d419b06"
   },
   "source": [
    "There are a few empty comments to be removed, otherwise sklearn will complain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "fdba531c-7ef2-4967-88e2-fc2b04f6f2ef",
    "_uuid": "1e1229f403225f1889c7a7b4fc9be90fda818af5"
   },
   "outputs": [],
   "source": [
    "COMMENT = 'comment_text'\n",
    "train[COMMENT].fillna(\"unknown\", inplace=True)\n",
    "test[COMMENT].fillna(\"unknown\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "480780f1-00c0-4f9a-81e5-fc1932516a80",
    "_uuid": "f2e77e8e6df5e29b620c7a2a0add1438c35af932"
   },
   "source": [
    "## Building the model\n",
    "\n",
    "I'll start by *TF-IDF* transformation using ngrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "b7f11db7-5c12-4eb8-9f2d-0323d629fed9",
    "_uuid": "b043a3fb66c443fab0129e863c134ec813dadb87"
   },
   "outputs": [],
   "source": [
    "import re, string\n",
    "re_tok = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\n",
    "def tokenize(s): return re_tok.sub(r' \\1 ', s).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "31ad6c98-d054-426c-b3bd-b3b18f52eb6f",
    "_uuid": "75f3f27d56fb2d7d539e65c292d9e77c92ceead3"
   },
   "outputs": [],
   "source": [
    "n = train.shape[0]\n",
    "vec = TfidfVectorizer(ngram_range=(1,2), tokenizer=tokenize,\n",
    "               min_df=3, max_df=0.9, strip_accents='unicode', use_idf=1,\n",
    "               smooth_idf=1, sublinear_tf=1, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the vectorizer\n",
    "vectorizer = 'vectorizer.joblib'\n",
    "joblib.dump(vec, open(vectorizer, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tdidf = vec.fit_transform(train[COMMENT])\n",
    "test_tdidf = vec.transform(test[COMMENT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4cf3ec26-8237-452b-90c9-831cb0297955",
    "_uuid": "6d215bc460e64d88b08f501d5c5a67c290e40635"
   },
   "source": [
    "This creates a *sparse matrix* with only a small number of non-zero elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "4c7bdbcc-4451-4477-944c-772e99bac777",
    "_uuid": "8816cc35f66b9fed9c12978fbdef5bb68fae10f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<159571x326105 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 9291686 stored elements in Compressed Sparse Row format>,\n",
       " <153164x326105 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 7741173 stored elements in Compressed Sparse Row format>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tdidf, test_tdidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "59131479-a861-4f46-add9-b2af09a51976",
    "_uuid": "5fc487461f4c6fdaea25f2cd471fc801856c6689"
   },
   "source": [
    "Here's the basic naive bayes feature equation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "45fc6070-ba13-455b-9274-5c2611e2809c",
    "_uuid": "8b277f01cecd575ed4fcae2e630c0dd8ce979793"
   },
   "outputs": [],
   "source": [
    "def pr(y_i, y):\n",
    "    p = x[y==y_i].sum(0)\n",
    "    return (p+1) / ((y==y_i).sum()+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "2299d24b-5515-4d37-92d9-e7f6b16a290a",
    "_uuid": "926eaa2e40e588f4ef2b86e0a28f8e575c9ed5f4"
   },
   "outputs": [],
   "source": [
    "x = train_tdidf\n",
    "test_x = test_tdidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c0b494ac-0dfc-4faa-a909-0a6d7696d1fc",
    "_uuid": "dc5cafeab86d17ac4f036d58658437636a885a87"
   },
   "source": [
    "Fit a model for one dependent at a time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "b756c889-a383-4952-9ee9-eca79fd3454f",
    "_uuid": "8652ab2f5f84e77fa395252be9b60be1e44fd583"
   },
   "outputs": [],
   "source": [
    "def get_mdl(y):\n",
    "    y = y.values\n",
    "    r = np.log(pr(1,y) / pr(0,y))\n",
    "    m = LogisticRegression(C=0.1, solver='sag')\n",
    "    x_nb = x.multiply(r)\n",
    "    return m.fit(x_nb, y), r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "33fd5f8c-adfc-45a1-9fde-1769a0993e76",
    "_uuid": "0fa103b5406aabdc36ea9ef21612d343e4982fc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit toxic\n",
      "fit severe_toxic\n",
      "fit obscene\n",
      "fit threat\n",
      "fit insult\n",
      "fit identity_hate\n"
     ]
    }
   ],
   "source": [
    "class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "preds = np.zeros((len(test), len(class_names)))\n",
    "\n",
    "for i, j in enumerate(class_names):\n",
    "    print('fit', j)\n",
    "    m,r = get_mdl(train[j])\n",
    "    # Save the model\n",
    "    filename = 'finalized_model_'+j+'.sav'\n",
    "    joblib.dump(m, filename)\n",
    "    preds[:,i] = m.predict_proba(test_x.multiply(r))[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1a99c4d9-916f-4189-9a25-fedcb7700336",
    "_uuid": "5525045116474e6d12b6edc890250d30c0790f06"
   },
   "source": [
    "And finally, create the submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "bc6a4575-fbbb-47ea-81ac-91fa702dc194",
    "_uuid": "5dd033a93e6cf32cdbdaa0a8b05cd8d27de2b21d"
   },
   "outputs": [],
   "source": [
    "submid = pd.DataFrame({'id': subm[\"id\"]})\n",
    "submission = pd.concat([submid, pd.DataFrame(preds, columns = class_names)], axis=1)\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1c345d02-b768-491c-8c03-8c3459a552a8",
    "_uuid": "adbbfb0156952a6a43833e337b8a418ccac257aa"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
