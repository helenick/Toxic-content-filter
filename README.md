# Toxic-content-filter
Discussing things can be difficult. Being anonymous on the internet can sometimes make people say nasty things that they normally would not in real life.
Platforms struggle to effectively facilitate conversations, leading many communities to limit or completely shut down user comments.
Let's filter out the hate from platforms. 
In this project a multi-headed model thatâ€™s capable of detecting different types of toxicity like threats, obscenity, insults, and identity-based hate is built.

Disclaimer: the dataset contains text that may be considered profane, vulgar, or offensive.
